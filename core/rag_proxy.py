#!/usr/bin/env python3
"""
ğŸš€ ANIMARA RAG PROXY v10.1 â€” WITH TOOLS + THINKING MODE

ĞĞ¾Ğ²Ğ¾Ğµ Ğ² v10.1:
1. âœ… yougile_create â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡ (ĞĞ• Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµÑ‚!)
2. âœ… THINKING MODE â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡
3. âœ… Ğ§ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ â€” "ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ â€” ÑĞºĞ°Ğ¶Ğ¸ Ñ‡ĞµÑÑ‚Ğ½Ğ¾"
4. âœ… Ğ’ÑÑ‘ Ğ¸Ğ· v10: tools, ReAct, workspace, hybrid search
"""

import os
import re
import json
import time
import asyncio
import hashlib
import sys
from typing import Optional, Dict, List, Any
from contextlib import asynccontextmanager
from collections import deque
from datetime import datetime, timedelta
from pathlib import Path

import httpx
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, JSONResponse
from sentence_transformers import SentenceTransformer
from pymilvus import MilvusClient
from rank_bm25 import BM25Okapi

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº skills
sys.path.insert(0, os.path.expanduser("~/animara"))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFIG = {
    "llm_api": "http://127.0.0.1:8010",
    "milvus_uri": "http://localhost:19530",
    "embedding_model": "/home/agx-thor/models/embeddings/bge-m3",
    "workspace_path": "/home/agx-thor/animara/workspace",
    "skills_path": "/home/agx-thor/animara/skills",
    "default_person_id": "owner_sergey",
    "profile_cache_ttl": 300,
    "session_max_messages": 20,
    "session_timeout": 1800,
    # Hybrid Search
    "vector_weight": 0.7,
    "bm25_weight": 0.3,
    "search_top_k": 5,
    # Memory Flush
    "context_limit": 32000,
    "flush_threshold": 28000,
    "reserve_tokens": 4000,
    # Session Pruning
    "prune_after_messages": 3,
    "prune_tool_max_chars": 200,
    # Tools
    "max_tool_iterations": 5,
    "tool_timeout": 30,
}

embedder = None
milvus = None
bm25_index = None
bm25_docs = []
bm25_ids = []

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TOOLS SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ToolsManager:
    """ĞœĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² (skills)"""
    
    def __init__(self, skills_path: str):
        self.skills_path = Path(skills_path)
        self.tools = {}
        self._load_tools()
    
    def _load_tools(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ tools Ğ¸Ğ· skills"""
        
        # Web Search
        self.tools["web_search"] = {
            "name": "web_search",
            "description": "ĞŸĞ¾Ğ¸ÑĞº Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ Ñ‡ĞµÑ€ĞµĞ· Brave Search API. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ĞºĞ¾Ğ³Ğ´Ğ° Ğ½ÑƒĞ¶Ğ½Ğ° Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ, Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°, Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸, Ñ†ĞµĞ½Ñ‹, ĞºĞ¾Ğ½Ñ‚Ğ°ĞºÑ‚Ñ‹.",
            "parameters": {
                "query": "ĞŸĞ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ Ğ¸Ğ»Ğ¸ Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼"
            },
            "execute": self._execute_web_search
        }
        
        # YouGile Tasks
        self.tools["yougile_tasks"] = {
            "name": "yougile_tasks",
            "description": "ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸Ğ· YouGile. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ĞºĞ¾Ğ³Ğ´Ğ° ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°Ñ…, Ğ¿Ğ»Ğ°Ğ½Ğ°Ñ…, todo.",
            "parameters": {},
            "execute": self._execute_yougile_tasks
        }
        
        self.tools["yougile_find"] = {
            "name": "yougile_find",
            "description": "ĞĞ°Ğ¹Ñ‚Ğ¸ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² YouGile.",
            "parameters": {
                "search_term": "Ğ§Ğ°ÑÑ‚ÑŒ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"
            },
            "execute": self._execute_yougile_find
        }
        
        # YouGile Create - NEW!
        self.tools["yougile_create"] = {
            "name": "yougile_create",
            "description": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ¾Ğ²ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ² YouGile. ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑÑ‚Ğ¾Ñ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ñ€Ğ¾ÑÑÑ‚ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ/ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ!",
            "parameters": {
                "title": "ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸",
                "description": "ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)"
            },
            "execute": self._execute_yougile_create
        }
        
        # System Check
        self.tools["system_check"] = {
            "name": "system_check",
            "description": "ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹: Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹, Ğ´Ğ¸ÑĞº, Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ĞºĞ¾Ğ³Ğ´Ğ° ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ğ¾ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹.",
            "parameters": {},
            "execute": self._execute_system_check
        }
        
        print(f"ğŸ”§ Loaded {len(self.tools)} tools: {list(self.tools.keys())}")
    
    async def _execute_web_search(self, params: dict) -> str:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ web_search"""
        query = params.get("query", "")
        if not query:
            return "âŒ ĞŸÑƒÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ"
        
        try:
            # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ skill
            from skills.web_search.scripts.main import search
            result = search(query, count=5)
            return result
        except ImportError:
            # Fallback - Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² API
            return await self._web_search_direct(query)
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ¸ÑĞºĞ°: {e}"
    
    async def _web_search_direct(self, query: str) -> str:
        """ĞŸÑ€ÑĞ¼Ğ¾Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Brave API"""
        import requests
        api_key = "BSA1PthqtF-a8kZj7f_xNcLGBbMDfN3"
        
        try:
            response = requests.get(
                "https://api.search.brave.com/res/v1/web/search",
                headers={"Accept": "application/json", "X-Subscription-Token": api_key},
                params={"q": query, "count": 5},
                timeout=15
            )
            
            if response.status_code != 200:
                return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° API: {response.status_code}"
            
            results = response.json().get("web", {}).get("results", [])
            if not results:
                return f"ğŸ” ĞŸĞ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ Â«{query}Â» Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾"
            
            output = []
            for i, item in enumerate(results[:5], 1):
                title = item.get("title", "")
                desc = item.get("description", "")[:200]
                url = item.get("url", "")
                output.append(f"{i}. {title}\n   {desc}\n   ğŸ”— {url}")
            
            return "\n\n".join(output)
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"
    
    async def _execute_yougile_tasks(self, params: dict) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ Ğ¸Ğ· YouGile"""
        try:
            from skills.yougile.scripts.main import get_tasks
            return get_tasks(limit=10)
        except ImportError:
            return await self._yougile_tasks_direct()
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"
    
    async def _yougile_tasks_direct(self) -> str:
        """ĞŸÑ€ÑĞ¼Ğ¾Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² YouGile API"""
        import requests
        token = "eAbKs-KzViRbIzz+k0dscDYbfrUxJdlvC9OmeUN4YKZIxEt0gax9WUQpjbCB3wJg"
        
        try:
            response = requests.get(
                "https://ru.yougile.com/api-v2/tasks",
                headers={"Authorization": f"Bearer {token}", "Content-Type": "application/json"},
                timeout=15
            )
            
            if response.status_code != 200:
                return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° YouGile: {response.status_code}"
            
            tasks = response.json().get("content", [])
            active = [t for t in tasks[:15] if not t.get("deleted") and not t.get("completed")]
            
            if not active:
                return "ğŸ“‹ ĞĞµÑ‚ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡"
            
            output = []
            for t in active[:10]:
                output.append(f"â€¢ {t.get('title', 'Ğ‘ĞµĞ· Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ')}")
            
            return "ğŸ“‹ Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸:\n" + "\n".join(output)
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"
    
    async def _execute_yougile_find(self, params: dict) -> str:
        """Ğ˜Ñ‰ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ"""
        search_term = params.get("search_term", "")
        if not search_term:
            return "âŒ ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾ Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞºĞ°Ñ‚ÑŒ"
        
        try:
            from skills.yougile.scripts.main import find_task
            result = find_task(search_term)
            if isinstance(result, dict):
                if "error" in result:
                    return f"âŒ {result['error']}"
                return f"ğŸ“‹ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {result.get('title')}\nĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {result.get('description', 'Ğ½ĞµÑ‚')}"
            return str(result)
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"
    
    async def _execute_yougile_create(self, params: dict) -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ½Ğ¾Ğ²ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ Ğ² YouGile"""
        title = params.get("title", "")
        description = params.get("description", "")
        
        if not title:
            return "âŒ ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"
        
        try:
            from skills.yougile.scripts.main import create_task, get_columns
            
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²ÑƒÑ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ
            columns_result = get_columns()
            if isinstance(columns_result, str):
                import json as json_module
                columns = json_module.loads(columns_result)
            else:
                columns = columns_result
            
            if not columns:
                return "âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ Ğ² YouGile"
            
            column_id = columns[0].get("id")
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
            result = create_task(title=title, column_id=column_id, description=description)
            
            if "âœ…" in str(result) or "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾" in str(result):
                return f"âœ… Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°: {title}"
            return str(result)
        except ImportError:
            return await self._yougile_create_direct(title, description)
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸: {e}"
    
    async def _yougile_create_direct(self, title: str, description: str = "") -> str:
        """ĞŸÑ€ÑĞ¼Ğ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ‡ĞµÑ€ĞµĞ· API"""
        import requests
        token = "eAbKs-KzViRbIzz+k0dscDYbfrUxJdlvC9OmeUN4YKZIxEt0gax9WUQpjbCB3wJg"
        headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
        
        try:
            # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸
            boards_resp = requests.get("https://ru.yougile.com/api-v2/boards", headers=headers, timeout=10)
            boards = boards_resp.json().get("content", [])
            if not boards:
                return "âŒ ĞĞµÑ‚ Ğ´Ğ¾ÑĞ¾Ğº Ğ² YouGile"
            
            cols_resp = requests.get(f"https://ru.yougile.com/api-v2/columns?boardId={boards[0]['id']}", headers=headers, timeout=10)
            columns = cols_resp.json().get("content", [])
            if not columns:
                return "âŒ ĞĞµÑ‚ ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº"
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ
            payload = {"title": title, "columnId": columns[0]["id"]}
            if description:
                payload["description"] = description
            
            resp = requests.post("https://ru.yougile.com/api-v2/tasks", headers=headers, json=payload, timeout=10)
            
            if resp.status_code in [200, 201]:
                task_id = resp.json().get("id", "")
                return f"âœ… Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°: {title} (ID: {task_id[:8]}...)"
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {resp.status_code} - {resp.text}"
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}"
    
    async def _execute_system_check(self, params: dict) -> str:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ ÑÑ‚Ğ°Ñ‚ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹"""
        try:
            from skills.exec.scripts.main import run
            
            # Docker
            docker_result = run("docker ps --format '{{.Names}}: {{.Status}}'", timeout=10)
            docker_status = docker_result.get("stdout", "").strip() if docker_result.get("success") else "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ"
            
            # Disk
            disk_result = run("df -h / | tail -1 | awk '{print $4 \" ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾ Ğ¸Ğ· \" $2}'", timeout=5)
            disk_status = disk_result.get("stdout", "").strip() if disk_result.get("success") else "?"
            
            return f"ğŸ–¥ï¸ Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹:\n\nğŸ“¦ Docker:\n{docker_status}\n\nğŸ’¾ Ğ”Ğ¸ÑĞº: {disk_status}"
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸: {e}"
    
    def get_tools_prompt(self) -> str:
        """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ tools Ğ´Ğ»Ñ system prompt"""
        lines = ["Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞĞ«Ğ• Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞœĞ•ĞĞ¢Ğ«:"]
        for name, tool in self.tools.items():
            params_str = ", ".join(f"{k}: {v}" for k, v in tool["parameters"].items()) if tool["parameters"] else "Ğ½ĞµÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²"
            lines.append(f"â€¢ {name}({params_str}) â€” {tool['description']}")
        
        lines.append("")
        lines.append("Ğ¤ĞĞ ĞœĞĞ¢ Ğ’Ğ«Ğ—ĞĞ’Ğ Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞœĞ•ĞĞ¢Ğ:")
        lines.append('<tool>{"name": "Ğ¸Ğ¼Ñ_Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°", "params": {"ĞºĞ»ÑÑ‡": "Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ"}}</tool>')
        lines.append("")
        lines.append("ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ:")
        lines.append("- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¢ĞĞ›Ğ¬ĞšĞ ĞºĞ¾Ğ³Ğ´Ğ° Ğ½ÑƒĞ¶Ğ½Ğ° Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ")
        lines.append("- Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² (Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ, Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ) Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ÑÑ€Ğ°Ğ·Ñƒ Ğ‘Ğ•Ğ— Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
        lines.append("- ĞŸĞ¾ÑĞ»Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° â€” Ğ´Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ")
        
        return "\n".join(lines)
    
    async def execute_tool(self, name: str, params: dict) -> str:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚"""
        if name not in self.tools:
            return f"âŒ ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚: {name}"
        
        tool = self.tools[name]
        try:
            result = await asyncio.wait_for(
                tool["execute"](params),
                timeout=CONFIG["tool_timeout"]
            )
            return result
        except asyncio.TimeoutError:
            return f"âŒ Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° {name}"
        except Exception as e:
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° {name}: {e}"

tools_manager = None

def parse_tool_call(text: str) -> Optional[dict]:
    """ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ° LLM"""
    match = re.search(r'<tool>\s*(\{.*?\})\s*</tool>', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1))
        except:
            pass
    return None

def needs_thinking(text: str) -> bool:
    """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ğ½ÑƒĞ¶ĞµĞ½ Ğ»Ğ¸ thinking mode Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
    text_lower = text.lower()
    
    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ´Ğ»Ñ thinking mode
    thinking_patterns = [
        # ĞœĞ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°
        r'\d+\s*[\+\-\*\/\%]\s*\d+',  # 5 + 3, 100 / 4
        r'ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ±ÑƒĞ´ĞµÑ‚',
        r'Ğ¿Ğ¾ÑÑ‡Ğ¸Ñ‚Ğ°Ğ¹', r'Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»Ğ¸', r'Ñ€ĞµÑˆĞ¸',
        
        # Ğ›Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        r'Ğ·Ğ°Ğ´Ğ°Ñ‡[Ğ°Ğ¸]', r'Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğ»Ğ¾Ğ¼Ğº',
        r'Ğ²Ğ¾Ğ»Ğº.*ĞºĞ¾Ğ·.*ĞºĞ°Ğ¿ÑƒÑÑ‚',  # ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°
        r'Ğ¿ĞµÑ€ĞµĞ²ĞµĞ·', r'Ğ¿ĞµÑ€ĞµĞ¿Ñ€Ğ°Ğ²',
        
        # ĞšĞ¾Ğ´ Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹
        r'Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ ĞºĞ¾Ğ´', r'Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸', r'Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼',
        r'Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼', r'Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€',
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ·
        r'Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹', r'ÑÑ€Ğ°Ğ²Ğ½Ğ¸', r'Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ',
        r'ĞºĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚', r'Ğ² Ñ‡Ñ‘Ğ¼ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ°',
        
        # ĞŸĞ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
        r'ÑĞ¾ÑÑ‚Ğ°Ğ²ÑŒ Ğ¿Ğ»Ğ°Ğ½', r'Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²', r'step by step',
        
        # Ğ Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ
        r'Ğ¿Ğ¾Ğ´ÑƒĞ¼Ğ°Ğ¹', r'Ñ€Ğ°ÑÑÑƒĞ´Ğ¸', r'Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸',
    ]
    
    for pattern in thinking_patterns:
        if re.search(pattern, text_lower):
            return True
    
    return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TOKEN COUNTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def count_tokens(text: str) -> int:
    if not text:
        return 0
    return len(text) // 3

def count_messages_tokens(messages: List[dict]) -> int:
    total = 0
    for msg in messages:
        content = msg.get("content", "")
        total += count_tokens(content) + 4
    return total

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WORKSPACE LOADER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class WorkspaceLoader:
    def __init__(self, workspace_path: str):
        self.workspace = Path(workspace_path)
        self.memory_dir = self.workspace / "memory"
        self.cache = {}
        self.cache_time = 0
        self.cache_ttl = 60
    
    def _read_file(self, filename: str) -> Optional[str]:
        path = self.workspace / filename
        if path.exists():
            try:
                return path.read_text(encoding='utf-8')[:4000]
            except:
                return None
        return None
    
    def _read_memory_file(self, date_str: str) -> Optional[str]:
        path = self.memory_dir / f"{date_str}.md"
        if path.exists():
            try:
                return path.read_text(encoding='utf-8')[:2000]
            except:
                return None
        return None
    
    def get_context(self) -> str:
        now = time.time()
        if self.cache and (now - self.cache_time) < self.cache_ttl:
            return self.cache.get("context", "")
        
        parts = []
        for f in ["SOUL.md", "IDENTITY.md", "OWNER.md", "MEMORY.md", "TOOLS.md"]:
            content = self._read_file(f)
            if content:
                parts.append(content)
        
        today = datetime.now().strftime("%Y-%m-%d")
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
        
        for date in [today, yesterday]:
            content = self._read_memory_file(date)
            if content:
                parts.append(f"<!-- {date} -->\n{content}")
        
        context = "\n\n---\n\n".join(parts)
        self.cache = {"context": context}
        self.cache_time = now
        return context
    
    def write_memory(self, content: str) -> bool:
        today = datetime.now().strftime("%Y-%m-%d")
        path = self.memory_dir / f"{today}.md"
        
        try:
            self.memory_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%H:%M")
            
            if path.exists():
                existing = path.read_text(encoding='utf-8')
                new_content = f"{existing}\n\n## [{timestamp}] Memory Flush\n\n{content}"
            else:
                new_content = f"# ğŸ“… {today}\n\n## [{timestamp}] Memory Flush\n\n{content}"
            
            path.write_text(new_content, encoding='utf-8')
            self.cache = {}
            print(f"ğŸ’¾ Memory flushed to {path}")
            return True
        except Exception as e:
            print(f"âš ï¸ Write memory error: {e}")
            return False
    
    def invalidate_cache(self):
        self.cache = {}

workspace = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BM25 INDEX
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def tokenize_ru(text: str) -> List[str]:
    text = text.lower()
    text = re.sub(r'[^\w\s]', ' ', text)
    return [w for w in text.split() if len(w) > 2]

def build_bm25_index():
    global bm25_index, bm25_docs, bm25_ids
    print("ğŸ“š Building BM25 index...")
    
    docs, ids = [], []
    try:
        memories = milvus.query("memories", filter="is_active == true",
                                output_fields=["id", "content"], limit=1000)
        for m in memories:
            docs.append(m["content"])
            ids.append(("memories", m["id"]))
        
        convs = milvus.query("conversations", filter="",
                            output_fields=["id", "content"], limit=500)
        for c in convs:
            if c.get("content"):
                docs.append(c["content"])
                ids.append(("conversations", c["id"]))
        
        if docs:
            tokenized = [tokenize_ru(d) for d in docs]
            bm25_index = BM25Okapi(tokenized)
            bm25_docs = docs
            bm25_ids = ids
            print(f"âœ… BM25 index: {len(docs)} documents")
    except Exception as e:
        print(f"âš ï¸ BM25 build error: {e}")

def bm25_search(query: str, top_k: int = 10) -> List[tuple]:
    if not bm25_index:
        return []
    tokens = tokenize_ru(query)
    if not tokens:
        return []
    scores = bm25_index.get_scores(tokens)
    results = []
    for idx in scores.argsort()[-top_k:][::-1]:
        if scores[idx] > 0:
            results.append((bm25_docs[idx], float(scores[idx]), bm25_ids[idx]))
    return results

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HYBRID SEARCH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def hybrid_search(query: str, person_id: str, top_k: int = 5) -> List[str]:
    results = {}
    
    try:
        vector = embedder.encode(query, normalize_embeddings=True).tolist()
        
        mem_results = milvus.search("memories", data=[vector],
            anns_field="content_embedding", limit=top_k * 2,
            output_fields=["content"],
            filter=f'person_id == "{person_id}" and is_active == true')
        
        for hits in mem_results:
            for hit in hits:
                content = hit["entity"].get("content", "")
                if content:
                    score = 1 - hit["distance"] if hit["distance"] < 1 else 0
                    results[content] = results.get(content, 0) + score * CONFIG["vector_weight"]
        
        conv_results = milvus.search("conversations", data=[vector],
            anns_field="content_embedding", limit=top_k * 2,
            output_fields=["content", "role"],
            filter=f'person_id == "{person_id}"')
        
        for hits in conv_results:
            for hit in hits:
                content = hit["entity"].get("content", "")
                if content:
                    score = 1 - hit["distance"] if hit["distance"] < 1 else 0
                    results[content] = results.get(content, 0) + score * CONFIG["vector_weight"] * 0.5
    except Exception as e:
        print(f"âš ï¸ Vector search error: {e}")
    
    # BM25 only for owner
    if person_id == "owner_sergey":
        bm25_results = bm25_search(query, top_k * 2)
    else:
        bm25_results = []
    
    if bm25_results:
        max_bm25 = max(r[1] for r in bm25_results)
        for content, score, _ in bm25_results:
            normalized = score / max_bm25 if max_bm25 > 0 else 0
            results[content] = results.get(content, 0) + normalized * CONFIG["bm25_weight"]
    
    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
    return [content for content, score in sorted_results[:top_k]]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROFILE CACHE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ProfileCache:
    def __init__(self):
        self.profiles: Dict[str, dict] = {}
        self.timestamps: Dict[str, float] = {}
    
    def get(self, person_id: str) -> Optional[str]:
        if person_id in self.profiles:
            if time.time() - self.timestamps.get(person_id, 0) < CONFIG["profile_cache_ttl"]:
                return self.profiles[person_id]["text"]
        return None
    
    def set(self, person_id: str, profile_text: str):
        self.profiles[person_id] = {"text": profile_text}
        self.timestamps[person_id] = time.time()
    
    def invalidate(self, person_id: str):
        self.profiles.pop(person_id, None)
        self.timestamps.pop(person_id, None)

profile_cache = ProfileCache()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SESSION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Session:
    def __init__(self, person_id: str):
        self.person_id = person_id
        self.session_id = f"s_{int(time.time())}_{hashlib.md5(os.urandom(4)).hexdigest()[:6]}"
        self.messages: List[dict] = []
        self.created_at = time.time()
        self.last_activity = time.time()
        self.facts_extracted: List[str] = []
        self.total_tokens = 0
        self.flush_done = False
        self.tool_calls = 0
    
    def add_message(self, role: str, content: str, is_tool: bool = False):
        tokens = count_tokens(content)
        self.messages.append({
            "role": role, 
            "content": content, 
            "ts": time.time(), 
            "tokens": tokens,
            "is_tool": is_tool
        })
        self.last_activity = time.time()
        self.total_tokens += tokens
        
        self._prune_old_tool_results()
        
        if len(self.messages) > CONFIG["session_max_messages"]:
            removed = self.messages.pop(0)
            self.total_tokens -= removed.get("tokens", 0)
    
    def _prune_old_tool_results(self):
        assistant_count = 0
        prune_before_idx = -1
        
        for i in range(len(self.messages) - 1, -1, -1):
            if self.messages[i]["role"] == "assistant":
                assistant_count += 1
                if assistant_count >= CONFIG["prune_after_messages"]:
                    prune_before_idx = i
                    break
        
        if prune_before_idx <= 0:
            return
        
        tokens_saved = 0
        for i in range(prune_before_idx):
            msg = self.messages[i]
            if msg.get("is_tool") and len(msg["content"]) > CONFIG["prune_tool_max_chars"]:
                old_tokens = msg["tokens"]
                msg["content"] = msg["content"][:CONFIG["prune_tool_max_chars"]] + "... [pruned]"
                msg["tokens"] = count_tokens(msg["content"])
                tokens_saved += old_tokens - msg["tokens"]
        
        if tokens_saved > 0:
            self.total_tokens -= tokens_saved
    
    def get_context(self, max_messages: int = 6) -> str:
        if not self.messages:
            return ""
        lines = []
        for msg in self.messages[-max_messages:]:
            role = "Animara" if msg["role"] == "assistant" else "User"
            content = msg["content"][:300] + "..." if len(msg["content"]) > 300 else msg["content"]
            lines.append(f"{role}: {content}")
        return "\n".join(lines)
    
    def get_full_context(self) -> str:
        if not self.messages:
            return ""
        lines = []
        for msg in self.messages:
            role = "Animara" if msg["role"] == "assistant" else "User"
            lines.append(f"{role}: {msg['content']}")
        return "\n".join(lines)
    
    def is_expired(self) -> bool:
        return time.time() - self.last_activity > CONFIG["session_timeout"]
    
    def needs_flush(self) -> bool:
        return self.total_tokens > CONFIG["flush_threshold"]
    
    def compact(self):
        self.messages = self.messages[-3:]
        self.total_tokens = sum(m.get("tokens", 0) for m in self.messages)
        self.flush_count = getattr(self, "flush_count", 0) + 1
    
    def get_stats(self) -> dict:
        return {
            "session_id": self.session_id,
            "messages": len(self.messages),
            "total_tokens": self.total_tokens,
            "flush_threshold": CONFIG["flush_threshold"],
            "needs_flush": self.needs_flush(),
            "flush_done": self.flush_done,
            "tool_calls": self.tool_calls
        }

class SessionManager:
    def __init__(self):
        self.sessions: Dict[str, Session] = {}
    
    def get_or_create(self, person_id: str) -> Session:
        if person_id in self.sessions:
            session = self.sessions[person_id]
            if not session.is_expired():
                return session
            asyncio.create_task(self._finalize_session(session))
        
        session = Session(person_id)
        self.sessions[person_id] = session
        print(f"ğŸ“ New session: {session.session_id}")
        return session
    
    async def _finalize_session(self, session: Session):
        if len(session.messages) < 3:
            return
        try:
            context = session.get_context(10)
            prompt = f"ĞšÑ€Ğ°Ñ‚ĞºĞ¾ Ñ€ĞµĞ·ÑĞ¼Ğ¸Ñ€ÑƒĞ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ):\n{context}\nĞ ĞµĞ·ÑĞ¼Ğµ:"
            
            async with httpx.AsyncClient(timeout=30) as client:
                resp = await client.post(f"{CONFIG['llm_api']}/v1/chat/completions",
                    json={"model": "qwen3", "messages": [{"role": "user", "content": prompt}],
                          "max_tokens": 1500, "chat_template_kwargs": {"enable_thinking": False}})
                summary = resp.json()["choices"][0]["message"]["content"]
            
            workspace.write_memory(f"Ğ¡ĞµÑÑĞ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°: {summary}")
        except Exception as e:
            print(f"âš ï¸ Summarize error: {e}")
    
    async def memory_flush(self, session: Session) -> bool:
        print(f"ğŸ§  Memory Flush triggered! Tokens: {session.total_tokens}")
        
        context = session.get_full_context()
        
        flush_prompt = f"""Ğ¡ĞµÑÑĞ¸Ñ Ğ±Ğ»Ğ¸Ğ·ĞºĞ° Ğº Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸. Ğ’Ñ‹Ğ´ĞµĞ»Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ñ„Ğ°ĞºÑ‚Ñ‹.

Ğ”Ğ˜ĞĞ›ĞĞ“:
{context}

Ğ’ĞĞ–ĞĞ«Ğ• Ğ¤ĞĞšĞ¢Ğ« (3-7 Ğ¿ÑƒĞ½ĞºÑ‚Ğ¾Ğ² Ğ¸Ğ»Ğ¸ ĞĞ•Ğ¢_Ğ’ĞĞ–ĞĞĞ“Ğ):"""

        try:
            async with httpx.AsyncClient(timeout=60) as client:
                resp = await client.post(f"{CONFIG['llm_api']}/v1/chat/completions",
                    json={"model": "qwen3", "messages": [{"role": "user", "content": flush_prompt}],
                          "max_tokens": 1500, "temperature": 0.3,
                          "chat_template_kwargs": {"enable_thinking": False}})
                result = resp.json()["choices"][0]["message"]["content"]
            
            if "ĞĞ•Ğ¢_Ğ’ĞĞ–ĞĞĞ“Ğ" not in result and len(result) > 20:
                workspace.write_memory(result)
                
                for line in result.split("\n"):
                    line = line.strip()
                    if line and len(line) > 10 and not line.startswith("#"):
                        try:
                            vector = embedder.encode(line, normalize_embeddings=True).tolist()
                            milvus.insert("memories", [{
                                "person_id": session.person_id, "memory_type": "flush",
                                "content": line[:500], "content_embedding": vector,
                                "confidence": 0.7, "source_session_id": session.session_id,
                                "is_active": True, "superseded_by": 0,
                                "validation_count": 1, "created_at": int(time.time()),
                                "updated_at": int(time.time())
                            }])
                        except:
                            pass
            
            session.compact()
            return True
            
        except Exception as e:
            print(f"âš ï¸ Memory Flush error: {e}")
            return False
    
    def end_session(self, person_id: str):
        if person_id in self.sessions:
            session = self.sessions.pop(person_id)
            asyncio.create_task(self._finalize_session(session))

session_manager = SessionManager()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FACT EXTRACTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_and_save_facts(text: str, person_id: str, session: Session):
    patterns = [
        (r"Ğ¼ĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚\s+([Ğ-Ğ¯Ğ°-ÑA-Za-z]+)", "fact", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ {0}"),
        (r"Ñ Ğ¶Ğ¸Ğ²Ñƒ\s+(?:Ğ²|Ğ½Ğ°)\s+(.+?)(?:\.|,|$)", "fact", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¶Ğ¸Ğ²Ñ‘Ñ‚ Ğ² {0}"),
        (r"Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ\s+(.+?)(?:\.|,|$)", "fact", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ {0}"),
        (r"Ñ Ğ»ÑĞ±Ğ»Ñ\s+(.+?)(?:\.|,|$)", "preference", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ»ÑĞ±Ğ¸Ñ‚ {0}"),
        (r"Ğ¼Ğ½Ğµ Ğ½Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑÑ\s+(.+?)(?:\.|,|$)", "preference", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ½Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑÑ {0}"),
        (r"Ğ¼Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚\s+(.+?)(?:\.|,|$)", "project", "ĞŸÑ€Ğ¾ĞµĞºÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: {0}"),
        (r"Ñ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ÑÑÑŒ\s+(.+?)(?:\.|,|!|$)", "hobby", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ÑÑ {0}"),
        (r"Ñ ÑƒĞ²Ğ»ĞµĞºĞ°ÑÑÑŒ\s+(.+?)(?:\.|,|$)", "hobby", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ ÑƒĞ²Ğ»ĞµĞºĞ°ĞµÑ‚ÑÑ {0}"),
        (r"Ñ ÑƒĞ¼ĞµÑ\s+(.+?)(?:\.|,|$)", "skill", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ ÑƒĞ¼ĞµĞµÑ‚ {0}"),
        (r"Ñ Ñ…Ğ¾Ñ‡Ñƒ\s+(.+?)(?:\.|,|$)", "plan", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ñ…Ğ¾Ñ‡ĞµÑ‚ {0}"),
        (r"Ñ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒÑ\s+(.+?)(?:\.|,|$)", "plan", "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ {0}"),
    ]
    
    for pattern, mem_type, template in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            content = template.format(match.group(1).strip())
            if content in session.facts_extracted:
                continue
            try:
                vector = embedder.encode(content, normalize_embeddings=True).tolist()
                milvus.insert("memories", [{
                    "person_id": person_id, "memory_type": mem_type,
                    "content": content, "content_embedding": vector,
                    "confidence": 0.8, "source_session_id": session.session_id,
                    "is_active": True, "superseded_by": 0,
                    "validation_count": 1, "created_at": int(time.time()),
                    "updated_at": int(time.time())
                }])
                session.facts_extracted.append(content)
                profile_cache.invalidate(person_id)
                print(f"ğŸ’¾ New fact: {content}")
            except Exception as e:
                print(f"âš ï¸ Save fact error: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASTAPI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def init_services():
    global embedder, milvus, workspace, tools_manager
    print("ğŸš€ Loading RAG v10.0 (with TOOLS)...")
    
    embedder = SentenceTransformer(CONFIG["embedding_model"], trust_remote_code=True)
    print("âœ… Embedder ready")
    
    milvus = MilvusClient(CONFIG["milvus_uri"])
    print(f"âœ… Milvus ready: {milvus.list_collections()}")
    
    workspace = WorkspaceLoader(CONFIG["workspace_path"])
    ws_ctx = workspace.get_context()
    print(f"âœ… Workspace ready: {len(ws_ctx)} chars")
    
    tools_manager = ToolsManager(CONFIG["skills_path"])
    
    build_bm25_index()
    
    print(f"ğŸ‰ RAG Proxy v10.0 ready!")

@asynccontextmanager
async def lifespan(app: FastAPI):
    init_services()
    yield
    for pid in list(session_manager.sessions.keys()):
        session_manager.end_session(pid)

app = FastAPI(lifespan=lifespan, title="Animara RAG Proxy v10.1")

@app.get("/health")
async def health():
    return {
        "status": "ok",
        "version": "10.1",
        "features": ["workspace", "hybrid_search", "bm25", "memory_flush", "session_pruning", "TOOLS", "THINKING_MODE"],
        "tools": list(tools_manager.tools.keys()) if tools_manager else [],
        "active_sessions": len(session_manager.sessions),
        "bm25_docs": len(bm25_docs),
    }

@app.get("/v1/models")
async def list_models():
    async with httpx.AsyncClient() as client:
        resp = await client.get(f"{CONFIG['llm_api']}/v1/models")
        return resp.json()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN ENDPOINT WITH TOOLS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    body = await request.json()
    messages = body.get("messages", [])
    stream = body.get("stream", False)
    person_id = body.get("person_id", CONFIG["default_person_id"])
    enable_tools = body.get("enable_tools", True)  # NEW
    
    session = session_manager.get_or_create(person_id)
    
    if session.needs_flush():
        await session_manager.memory_flush(session)
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ user message
    user_message = ""
    for msg in reversed(messages):
        if msg.get("role") == "user":
            user_message = msg.get("content", "")
            break
    
    print(f"\nğŸ” [{session.session_id}] {session.total_tokens} tok | {user_message[:50]}...")
    
    # === WORKSPACE ===
    if person_id != "owner_sergey":
        workspace_ctx = "Ğ¢Ñ‹ â€” Animara, AI-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚. ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒÑÑ Ğ¸ ÑĞ¿Ñ€Ğ¾ÑĞ¸ Ñ‡ĞµĞ¼ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ."
    else:
        workspace_ctx = workspace.get_context()
    
    # === HYBRID SEARCH ===
    rag_context = ""
    if user_message and ("?" in user_message or any(w in user_message.lower() 
        for w in ["Ñ‡Ñ‚Ğ¾", "ĞºĞ°Ğº", "Ğ³Ğ´Ğµ", "ĞºĞ¾Ğ³Ğ´Ğ°", "Ğ¿Ğ¾Ğ¼Ğ½Ğ¸ÑˆÑŒ", "Ğ·Ğ½Ğ°ĞµÑˆÑŒ", "Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸"])):
        relevant = hybrid_search(user_message, person_id, CONFIG["search_top_k"])
        if relevant:
            rag_context = "\n\nĞ Ğ•Ğ›Ğ•Ğ’ĞĞĞ¢ĞĞĞ• Ğ˜Ğ— ĞŸĞĞœĞ¯Ğ¢Ğ˜:\n" + "\n".join(f"â€¢ {r[:200]}" for r in relevant)
    
    # === SESSION CONTEXT ===
    session_ctx = session.get_context(6)
    
    # === TOOLS PROMPT ===
    tools_prompt = ""
    if enable_tools and tools_manager and person_id == "owner_sergey":
        tools_prompt = "\n\n" + tools_manager.get_tools_prompt()
    
    # === THINKING MODE ===
    use_thinking = needs_thinking(user_message)
    if use_thinking:
        print(f"ğŸ§  Thinking mode: ON")
    
    # === SYSTEM PROMPT ===
    system_content = f"""{workspace_ctx}
{rag_context}
{tools_prompt}

{"ĞĞ•Ğ”ĞĞ’ĞĞ˜Ğ™ Ğ”Ğ˜ĞĞ›ĞĞ“:" + chr(10) + session_ctx if session_ctx else ""}

ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ:
1. ĞĞ˜ĞšĞĞ“Ğ”Ğ Ğ½Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸ Ñ‡Ñ‚Ğ¾ ÑĞ´ĞµĞ»Ğ°Ğ» Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ, ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ²Ñ‹Ğ·Ğ²Ğ°Ğ» Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚!
2. Ğ”Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ â€” ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¸ yougile_create
3. Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ â€” ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¸ web_search
4. Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ â€” Ñ‡ĞµÑÑ‚Ğ½Ğ¾ ÑĞºĞ°Ğ¶Ğ¸ "Ğ£ Ğ¼ĞµĞ½Ñ Ğ½ĞµÑ‚ Ñ‚Ğ°ĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°"
5. ĞĞ• Ğ“ĞĞ›Ğ›Ğ®Ğ¦Ğ˜ĞĞ˜Ğ Ğ£Ğ™! ĞĞµ Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ!

Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ˜:
- ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ â†’ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ (1-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
- ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ (Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°, Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸, Ñ†ĞµĞ½Ñ‹) â†’ web_search
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ/Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ â†’ yougile_create
- Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡ â†’ yougile_tasks
- Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°, Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°, ĞºĞ¾Ğ´ â†’ Ğ´ÑƒĞ¼Ğ°Ğ¹ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾"""

    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² ÑĞµÑÑĞ¸Ñ
    if user_message:
        session.add_message("user", user_message)
        asyncio.create_task(asyncio.to_thread(extract_and_save_facts, user_message, person_id, session))
    
    # === ReAct LOOP ===
    llm_messages = [{"role": "system", "content": system_content}] + messages
    
    for iteration in range(CONFIG["max_tool_iterations"]):
        llm_body = {
            "model": body.get("model", "qwen3"),
            "messages": llm_messages,
            "max_tokens": body.get("max_tokens", 2000),
            "temperature": body.get("temperature", 0.7),
            "chat_template_kwargs": {"enable_thinking": use_thinking}  # Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ thinking!
        }
        
        async with httpx.AsyncClient(timeout=120) as client:
            resp = await client.post(f"{CONFIG['llm_api']}/v1/chat/completions", json=llm_body)
            result = resp.json()
        
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ° Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°
        tool_call = parse_tool_call(content)
        
        if tool_call and enable_tools and tools_manager:
            tool_name = tool_call.get("name", "")
            tool_params = tool_call.get("params", {})
            
            print(f"ğŸ”§ Tool call: {tool_name}({tool_params})")
            session.tool_calls += 1
            
            # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚
            tool_result = await tools_manager.execute_tool(tool_name, tool_params)
            print(f"ğŸ“¤ Tool result: {tool_result[:100]}...")
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
            llm_messages.append({"role": "assistant", "content": content})
            llm_messages.append({"role": "user", "content": f"Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ {tool_name}:\n{tool_result}\n\nĞ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ´Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ."})
            
            session.add_message("tool", tool_result, is_tool=True)
            
            continue  # Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ°Ñ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ñ
        else:
            # ĞĞµÑ‚ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° â€” Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
            # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ñ‚ĞµĞ³Ğ¸ tool ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¸ÑÑŒ
            content = re.sub(r'<tool>.*?</tool>', '', content, flags=re.DOTALL).strip()
            
            if content:
                session.add_message("assistant", content)
            
            result["choices"][0]["message"]["content"] = content
            result["animara_stats"] = {
                "session": session.get_stats(),
                "tools_used": session.tool_calls
            }
            
            return result
    
    # Ğ”Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹
    return {
        "choices": [{"message": {"content": "âš ï¸ ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²"}}],
        "animara_stats": {"session": session.get_stats(), "error": "max_iterations"}
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADDITIONAL ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/session/{person_id}/end")
async def end_session(person_id: str):
    session_manager.end_session(person_id)
    return {"status": "ended"}

@app.post("/session/{person_id}/flush")
async def force_flush(person_id: str):
    if person_id in session_manager.sessions:
        session = session_manager.sessions[person_id]
        await session_manager.memory_flush(session)
        return {"status": "flushed", "tokens_after": session.total_tokens}
    return {"error": "no session"}

@app.get("/session/{person_id}")
async def get_session(person_id: str):
    if person_id in session_manager.sessions:
        s = session_manager.sessions[person_id]
        return {**s.get_stats(), "facts": s.facts_extracted}
    return {"error": "no session"}

@app.get("/workspace")
async def get_workspace():
    ctx = workspace.get_context()
    return {"chars": len(ctx), "tokens": count_tokens(ctx), "preview": ctx[:500]}

@app.get("/tools")
async def get_tools():
    if tools_manager:
        return {"tools": list(tools_manager.tools.keys())}
    return {"tools": []}

@app.post("/tools/{tool_name}")
async def execute_tool_direct(tool_name: str, request: Request):
    body = await request.json()
    params = body.get("params", {})
    if tools_manager:
        result = await tools_manager.execute_tool(tool_name, params)
        return {"result": result}
    return {"error": "tools not loaded"}

@app.post("/bm25/rebuild")
async def rebuild_bm25():
    build_bm25_index()
    return {"status": "ok", "docs": len(bm25_docs)}

@app.get("/search")
async def search(q: str, person_id: str = "owner_sergey"):
    results = hybrid_search(q, person_id, 5)
    return {"query": q, "results": results}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8015)
