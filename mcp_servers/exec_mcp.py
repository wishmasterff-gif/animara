#!/usr/bin/env python3
"""
ğŸ”§ ANIMARA Exec MCP Server

MCP ÑĞµÑ€Ğ²ĞµÑ€ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ shell ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´ Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ¾Ğ¹ Ğ¾Ñ‚ Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ñ… Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹.
Ğ—Ğ°Ğ¿ÑƒÑĞº: python3 exec_mcp.py

Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸:
- run: Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ shell ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ
- docker_ps: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹
- disk_usage: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸ÑĞºĞ°
- memory_usage: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
- gpu_status: ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ GPU (nvidia-smi)
"""

import os
import asyncio
import subprocess
import shlex
from typing import Optional

# MCP SDK
try:
    from mcp.server import Server
    from mcp.server.stdio import stdio_server
    from mcp.types import Tool, TextContent
except ImportError:
    print("ERROR: MCP SDK not installed. Run: pip install mcp")
    exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ Ğ‘Ğ•Ğ—ĞĞŸĞĞ¡ĞĞĞ¡Ğ¢Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ—ĞĞŸĞ Ğ•Ğ©Ğ•ĞĞ« Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ
BLOCKED_COMMANDS = [
    "rm -rf /",
    "rm -rf /*",
    "mkfs",
    "> /dev/sda",
    "dd if=/dev/zero",
    ":(){:|:&};:",  # Fork bomb
    "chmod -R 777 /",
    "chown -R",
]

# ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ (Ğ½Ğ¾ Ğ¼Ñ‹ Ğ¸Ñ… Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞµĞ¼)
DANGEROUS_PATTERNS = [
    "rm -rf",
    "rm -r /",
    "sudo rm",
    "sudo mkfs",
    "sudo dd",
    "shutdown",
    "reboot",
    "init 0",
    "init 6",
    "systemctl stop",
    "kill -9 1",
]

# ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ timeout
MAX_TIMEOUT = 60

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP Ğ¡Ğ•Ğ Ğ’Ğ•Ğ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

server = Server("exec")


@server.list_tools()
async def list_tools() -> list[Tool]:
    """Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²"""
    return [
        Tool(
            name="run",
            description="Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ shell ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ. ĞĞ¿Ğ°ÑĞ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ (rm -rf, sudo rm) Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸.",
            inputSchema={
                "type": "object",
                "properties": {
                    "command": {
                        "type": "string",
                        "description": "Shell ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ´Ğ»Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ"
                    },
                    "timeout": {
                        "type": "integer",
                        "description": "Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ… (default: 30, max: 60)",
                        "default": 30
                    }
                },
                "required": ["command"]
            }
        ),
        Tool(
            name="docker_ps",
            description="ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²",
            inputSchema={
                "type": "object",
                "properties": {
                    "all": {
                        "type": "boolean",
                        "description": "ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµ ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ",
                        "default": False
                    }
                }
            }
        ),
        Tool(
            name="disk_usage",
            description="ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸ÑĞºĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°",
            inputSchema={
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ĞŸÑƒÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ (default: /)",
                        "default": "/"
                    }
                }
            }
        ),
        Tool(
            name="memory_usage",
            description="ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="gpu_status",
            description="ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ GPU Ñ‡ĞµÑ€ĞµĞ· nvidia-smi",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
    ]


@server.call_tool()
async def call_tool(name: str, arguments: dict) -> list[TextContent]:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ² Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²"""
    
    try:
        if name == "run":
            result = run_command(
                arguments.get("command", ""),
                arguments.get("timeout", 30)
            )
        elif name == "docker_ps":
            result = docker_ps(arguments.get("all", False))
        elif name == "disk_usage":
            result = disk_usage(arguments.get("path", "/"))
        elif name == "memory_usage":
            result = memory_usage()
        elif name == "gpu_status":
            result = gpu_status()
        else:
            result = f"âŒ Unknown tool: {name}"
        
        return [TextContent(type="text", text=result)]
    
    except Exception as e:
        return [TextContent(type="text", text=f"âŒ Error: {str(e)}")]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def is_command_safe(command: str) -> tuple[bool, str]:
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹"""
    
    cmd_lower = command.lower().strip()
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
    for blocked in BLOCKED_COMMANDS:
        if blocked in cmd_lower:
            return False, f"â›” ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°: ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ '{blocked}'"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹
    for pattern in DANGEROUS_PATTERNS:
        if pattern in cmd_lower:
            return False, f"â›” ĞĞ¿Ğ°ÑĞ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ '{pattern}'. Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ."
    
    return True, ""


def run_command(command: str, timeout: int = 30) -> str:
    """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ shell ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ"""
    
    if not command.strip():
        return "âŒ ĞŸÑƒÑÑ‚Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸
    is_safe, error_msg = is_command_safe(command)
    if not is_safe:
        return error_msg
    
    # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ timeout
    timeout = min(timeout, MAX_TIMEOUT)
    
    try:
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=os.path.expanduser("~")
        )
        
        output = ""
        if result.stdout:
            output += result.stdout
        if result.stderr:
            if output:
                output += "\n--- STDERR ---\n"
            output += result.stderr
        
        if not output:
            output = "(ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ°, Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹)"
        
        # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°
        if len(output) > 5000:
            output = output[:5000] + "\n... (Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½)"
        
        return f"$ {command}\n\n{output}"
    
    except subprocess.TimeoutExpired:
        return f"âŒ Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚: ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞ»Ğ°ÑÑŒ Ğ´Ğ¾Ğ»ÑŒÑˆĞµ {timeout} ÑĞµĞºÑƒĞ½Ğ´"
    except Exception as e:
        return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ: {e}"


def docker_ps(show_all: bool = False) -> str:
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Docker ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹"""
    
    cmd = "docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'"
    if show_all:
        cmd = "docker ps -a --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'"
    
    return run_command(cmd)


def disk_usage(path: str = "/") -> str:
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸ÑĞºĞ°"""
    
    # Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¿ÑƒÑ‚ĞµĞ¹ Ñ Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¼Ğ¸ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼Ğ¸
    safe_path = shlex.quote(path)
    return run_command(f"df -h {safe_path}")


def memory_usage() -> str:
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸"""
    
    return run_command("free -h")


def gpu_status() -> str:
    """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ GPU"""
    
    return run_command("nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """Ğ—Ğ°Ğ¿ÑƒÑĞº MCP ÑĞµÑ€Ğ²ĞµÑ€Ğ°"""
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            server.create_initialization_options()
        )


if __name__ == "__main__":
    asyncio.run(main())
