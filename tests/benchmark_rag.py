import time
import torch
import os
from sentence_transformers import SentenceTransformer, CrossEncoder

# –ü—É—Ç–∏ –∏–∑ —Ç–≤–æ–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞
EMBED_MODEL_PATH = os.path.expanduser("~/models/embeddings/bge-m3")
RERANK_MODEL_PATH = os.path.expanduser("~/models/rerankers/bge-reranker-v2-m3")

def benchmark_rag():
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ RAG –ø–∞–π–ø–ª–∞–π–Ω–∞...")
    
    test_query = "–ö–∞–∫–∏–µ –ø–ª–∞–Ω—ã –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é —Å–∏—Å—Ç–µ–º—ã –ê–Ω–∏–º–∞—Ä–∞?"
    # –ò–º–∏—Ç–∏—Ä—É–µ–º 10 –∫—É—Å–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤ Milvus
    test_chunks = [f"–§—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ {i}: –ø—Ä–æ–µ–∫—Ç Animara —Ä–∞–∑–≤–∏–≤–∞–µ—Ç—Å—è –≤ –£–±—É–¥–µ." for i in range(10)]

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–∑–∞–º–µ—Ä—è–µ–º, —Å–∫–æ–ª—å–∫–æ –æ–Ω–∏ –∑–∞–Ω–∏–º–∞—é—Ç –≤ –ø–∞–º—è—Ç–∏)
    print("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –≤ –ø–∞–º—è—Ç—å...")
    start_load = time.perf_counter()
    model = SentenceTransformer(EMBED_MODEL_PATH)
    reranker = CrossEncoder(RERANK_MODEL_PATH)
    print(f"‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞ {time.perf_counter() - start_load:.2f} —Å–µ–∫")

    # 2. –ó–∞–º–µ—Ä Embedding
    start_emb = time.perf_counter()
    query_vector = model.encode(test_query)
    end_emb = time.perf_counter()
    print(f"üîπ [1/3] Embedding (BGE-M3): {end_emb - start_emb:.4f} —Å–µ–∫")

    # 3. –ó–∞–º–µ—Ä Reranking (—Å–∞–º–æ–µ —Ç—è–∂–µ–ª–æ–µ –º–µ—Å—Ç–æ)
    start_rerank = time.perf_counter()
    pairs = [[test_query, chunk] for chunk in test_chunks]
    scores = reranker.predict(pairs)
    end_rerank = time.perf_counter()
    print(f"üîπ [2/3] Reranking (10 –∫—É—Å–∫–æ–≤): {end_rerank - start_rerank:.4f} —Å–µ–∫")

    # 4. –ò—Ç–æ–≥–æ–≤–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ (–±–µ–∑ —É—á–µ—Ç–∞ LLM)
    print(f"\nüìä –ò—Ç–æ–≥–æ –Ω–∞ –ø–æ–∏—Å–∫ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ: {end_rerank - start_emb:.4f} —Å–µ–∫")

if __name__ == "__main__":
    benchmark_rag()
